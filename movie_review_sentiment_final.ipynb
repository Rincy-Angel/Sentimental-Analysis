{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "movie review sentiment final.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rincy-Angel/Sentimental-Analysis/blob/master/movie_review_sentiment_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjfx0M5u1dG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import nltk.classify.util\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4RY3-J91dHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#movie_reviews is an nltk provided data. you dont have to read the file\n",
        "#you can directly start working on it\n",
        "movie_reviews.words()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIZYVMw1dHU",
        "colab_type": "code",
        "colab": {},
        "outputId": "7f62cce2-a6b7-4674-ea0d-4148fef98813"
      },
      "source": [
        "movie_reviews.categories()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg', 'pos']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3GEfP_t1dHj",
        "colab_type": "code",
        "colab": {},
        "outputId": "a911fdcc-d25c-4f14-9bb3-ce0e6ede354d"
      },
      "source": [
        "#to print the different files in the folder(1-5)\n",
        "movie_reviews.fileids()[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg/cv000_29416.txt',\n",
              " 'neg/cv001_19502.txt',\n",
              " 'neg/cv002_17424.txt',\n",
              " 'neg/cv003_12683.txt',\n",
              " 'neg/cv004_12641.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HFp7RD41dHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to get the frequency of most repeated words\n",
        "all_words = movie_reviews.words()\n",
        "\n",
        "freq = nltk.FreqDist(all_words)\n",
        "\n",
        "freq.most_common(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAz7pNEe1dH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating dictionary for the words and removing the stop words\n",
        "#the dict() handles repetition\n",
        "#we are doing this because the naivebayes classifier expects the input in \n",
        "#this format\n",
        "def create_dictionary(words):\n",
        "    useful_words = [word for word in words if word not in stopwords.words(\"english\")]\n",
        "    my_dict = dict([word,True] for word in useful_words)\n",
        "    return my_dict\n",
        "\n",
        "create_dictionary(['sneha','is','an','idiot'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvdvlOR51dIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#here we are storing the negative words separately\n",
        "neg_reviews = []\n",
        "for fileid in movie_reviews.fileids('neg'):\n",
        "    words = movie_reviews.words(fileid)\n",
        "    neg_reviews.append((create_dictionary(words),'negative'))\n",
        "    \n",
        "#print(neg_reviews[0])\n",
        "print(len(neg_reviews))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omxgt1pm1dII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#storing the positive words separately\n",
        "pos_reviews = []\n",
        "for fileid in movie_reviews.fileids('pos'):\n",
        "    words = movie_reviews.words(fileid)\n",
        "    pos_reviews.append((create_dictionary(words),'positive'))\n",
        "    \n",
        "#print(neg_reviews[0])\n",
        "print(len(pos_reviews))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EZIhFVe1dIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#75% data is taken for training while the remaining 25% taken for testing\n",
        "train = neg_reviews[:500]+ pos_reviews[:500]\n",
        "test = neg_reviews[:500]+ pos_reviews[:500]\n",
        "\n",
        "print(len(train),len(test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWqH3wEs1dIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initializing the naive bayes classifier and assigning the train data\n",
        "classifier = NaiveBayesClassifier.train(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoZdvPAE1dIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculating the accuracy of the algorithm\n",
        "accuracy = nltk.classify.util.accuracy(classifier,train)\n",
        "print(accuracy*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9MQoNEe1dIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#''' are used for multiple lines\n",
        "review = '''I tried opening Bhuvan website, thinking that the plugin might kick in, but unfortunately the application does not seem to support either Chrome or Firefox.'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXyEaD0t1dId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word = word_tokenize(review)\n",
        "print(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLXWiXiR1dIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word = create_dictionary(word)\n",
        "print(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CF16k-r1dIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#classify() classifies the given input\n",
        "classifier.classify(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ9Ar2Jy1dIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review1 = \"very boring movie.after sura puli will add in that list\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSmQbsHX1dIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word1 = word_tokenize(review1)\n",
        "print(word1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wE01shd1dI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word1 = create_dictionary(word1)\n",
        "print(word1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbm8g-EL1dI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.classify(word1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wpaz4T11dJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}